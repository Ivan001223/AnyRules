#!/usr/bin/env python3

"""
æ—¥å¿—åˆ†æè„šæœ¬
ç”¨æ³•: python log-analyzer.py <log-file> [--format nginx|apache|json] [--errors-only] [--top 10]
"""

import re
import json
import argparse
import sys
from collections import Counter, defaultdict
from datetime import datetime
import geoip2.database
import geoip2.errors

class LogAnalyzer:
    def __init__(self, log_file, log_format='nginx', errors_only=False, top_count=10):
        self.log_file = log_file
        self.log_format = log_format
        self.errors_only = errors_only
        self.top_count = top_count
        
        # æ—¥å¿—æ ¼å¼æ­£åˆ™è¡¨è¾¾å¼
        self.patterns = {
            'nginx': r'(?P<ip>\d+\.\d+\.\d+\.\d+) - - \[(?P<timestamp>[^\]]+)\] "(?P<method>\w+) (?P<url>[^"]*)" (?P<status>\d+) (?P<size>\d+) "(?P<referer>[^"]*)" "(?P<user_agent>[^"]*)"',
            'apache': r'(?P<ip>\d+\.\d+\.\d+\.\d+) - - \[(?P<timestamp>[^\]]+)\] "(?P<method>\w+) (?P<url>[^"]*)" (?P<status>\d+) (?P<size>\d+)',
            'json': None  # JSONæ ¼å¼ç‰¹æ®Šå¤„ç†
        }
        
        # ç»Ÿè®¡æ•°æ®
        self.stats = {
            'total_requests': 0,
            'status_codes': Counter(),
            'ips': Counter(),
            'urls': Counter(),
            'user_agents': Counter(),
            'methods': Counter(),
            'errors': [],
            'hourly_requests': defaultdict(int),
            'response_sizes': []
        }
    
    def parse_nginx_log(self, line):
        """è§£æNginxæ—¥å¿—"""
        pattern = self.patterns['nginx']
        match = re.match(pattern, line)
        if match:
            return match.groupdict()
        return None
    
    def parse_apache_log(self, line):
        """è§£æApacheæ—¥å¿—"""
        pattern = self.patterns['apache']
        match = re.match(pattern, line)
        if match:
            return match.groupdict()
        return None
    
    def parse_json_log(self, line):
        """è§£æJSONæ—¥å¿—"""
        try:
            return json.loads(line)
        except json.JSONDecodeError:
            return None
    
    def parse_line(self, line):
        """è§£æå•è¡Œæ—¥å¿—"""
        if self.log_format == 'nginx':
            return self.parse_nginx_log(line)
        elif self.log_format == 'apache':
            return self.parse_apache_log(line)
        elif self.log_format == 'json':
            return self.parse_json_log(line)
        return None
    
    def is_error_status(self, status):
        """åˆ¤æ–­æ˜¯å¦ä¸ºé”™è¯¯çŠ¶æ€ç """
        try:
            status_code = int(status)
            return status_code >= 400
        except ValueError:
            return False
    
    def get_hour_from_timestamp(self, timestamp):
        """ä»æ—¶é—´æˆ³æå–å°æ—¶"""
        try:
            if self.log_format in ['nginx', 'apache']:
                # æ ¼å¼: 10/Oct/2023:14:30:45 +0000
                dt = datetime.strptime(timestamp.split()[0], '%d/%b/%Y:%H:%M:%S')
                return dt.hour
            elif self.log_format == 'json':
                # å‡è®¾JSONä¸­æœ‰timestampå­—æ®µ
                dt = datetime.fromisoformat(timestamp.replace('Z', '+00:00'))
                return dt.hour
        except (ValueError, AttributeError):
            pass
        return 0
    
    def analyze_log(self):
        """åˆ†ææ—¥å¿—æ–‡ä»¶"""
        print(f"ğŸ“Š å¼€å§‹åˆ†ææ—¥å¿—æ–‡ä»¶: {self.log_file}")
        
        try:
            with open(self.log_file, 'r', encoding='utf-8', errors='ignore') as f:
                for line_num, line in enumerate(f, 1):
                    line = line.strip()
                    if not line:
                        continue
                    
                    parsed = self.parse_line(line)
                    if not parsed:
                        continue
                    
                    # ç»Ÿä¸€å­—æ®µå
                    ip = parsed.get('ip') or parsed.get('remote_addr')
                    status = parsed.get('status') or parsed.get('status_code')
                    url = parsed.get('url') or parsed.get('request_uri')
                    method = parsed.get('method') or parsed.get('request_method')
                    user_agent = parsed.get('user_agent')
                    timestamp = parsed.get('timestamp') or parsed.get('time')
                    size = parsed.get('size') or parsed.get('body_bytes_sent')
                    
                    # å¦‚æœåªåˆ†æé”™è¯¯ï¼Œè·³è¿‡æ­£å¸¸è¯·æ±‚
                    if self.errors_only and not self.is_error_status(status):
                        continue
                    
                    # æ›´æ–°ç»Ÿè®¡
                    self.stats['total_requests'] += 1
                    
                    if status:
                        self.stats['status_codes'][status] += 1
                        
                        # è®°å½•é”™è¯¯è¯¦æƒ…
                        if self.is_error_status(status):
                            self.stats['errors'].append({
                                'line': line_num,
                                'ip': ip,
                                'status': status,
                                'url': url,
                                'timestamp': timestamp
                            })
                    
                    if ip:
                        self.stats['ips'][ip] += 1
                    
                    if url:
                        self.stats['urls'][url] += 1
                    
                    if method:
                        self.stats['methods'][method] += 1
                    
                    if user_agent:
                        self.stats['user_agents'][user_agent] += 1
                    
                    if timestamp:
                        hour = self.get_hour_from_timestamp(timestamp)
                        self.stats['hourly_requests'][hour] += 1
                    
                    if size and size.isdigit():
                        self.stats['response_sizes'].append(int(size))
                    
                    # è¿›åº¦æ˜¾ç¤º
                    if line_num % 10000 == 0:
                        print(f"å·²å¤„ç† {line_num} è¡Œ...")
        
        except FileNotFoundError:
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {self.log_file}")
            sys.exit(1)
        except Exception as e:
            print(f"âŒ åˆ†æå¤±è´¥: {e}")
            sys.exit(1)
    
    def get_geo_info(self, ip):
        """è·å–IPåœ°ç†ä½ç½®ä¿¡æ¯"""
        try:
            # éœ€è¦ä¸‹è½½GeoLite2æ•°æ®åº“
            # wget https://github.com/P3TERX/GeoLite.mmdb/raw/download/GeoLite2-City.mmdb
            with geoip2.database.Reader('GeoLite2-City.mmdb') as reader:
                response = reader.city(ip)
                return f"{response.country.name}, {response.city.name}"
        except (geoip2.errors.AddressNotFoundError, FileNotFoundError):
            return "Unknown"
    
    def print_report(self):
        """æ‰“å°åˆ†ææŠ¥å‘Š"""
        print("\n" + "="*60)
        print("ğŸ“ˆ æ—¥å¿—åˆ†ææŠ¥å‘Š")
        print("="*60)
        
        # åŸºæœ¬ç»Ÿè®¡
        print(f"ğŸ“Š æ€»è¯·æ±‚æ•°: {self.stats['total_requests']:,}")
        print(f"âŒ é”™è¯¯è¯·æ±‚æ•°: {len(self.stats['errors']):,}")
        
        if self.stats['response_sizes']:
            avg_size = sum(self.stats['response_sizes']) / len(self.stats['response_sizes'])
            print(f"ğŸ“¦ å¹³å‡å“åº”å¤§å°: {avg_size:.2f} bytes")
        
        # çŠ¶æ€ç ç»Ÿè®¡
        if self.stats['status_codes']:
            print(f"\nğŸ“‹ çŠ¶æ€ç åˆ†å¸ƒ (Top {self.top_count}):")
            for status, count in self.stats['status_codes'].most_common(self.top_count):
                percentage = (count / self.stats['total_requests']) * 100
                print(f"  {status}: {count:,} ({percentage:.1f}%)")
        
        # IPç»Ÿè®¡
        if self.stats['ips']:
            print(f"\nğŸŒ è®¿é—®IP (Top {self.top_count}):")
            for ip, count in self.stats['ips'].most_common(self.top_count):
                percentage = (count / self.stats['total_requests']) * 100
                print(f"  {ip}: {count:,} ({percentage:.1f}%)")
        
        # URLç»Ÿè®¡
        if self.stats['urls']:
            print(f"\nğŸ”— è®¿é—®URL (Top {self.top_count}):")
            for url, count in self.stats['urls'].most_common(self.top_count):
                percentage = (count / self.stats['total_requests']) * 100
                url_display = url[:50] + "..." if len(url) > 50 else url
                print(f"  {url_display}: {count:,} ({percentage:.1f}%)")
        
        # è¯·æ±‚æ–¹æ³•ç»Ÿè®¡
        if self.stats['methods']:
            print(f"\nğŸ“ è¯·æ±‚æ–¹æ³•:")
            for method, count in self.stats['methods'].most_common():
                percentage = (count / self.stats['total_requests']) * 100
                print(f"  {method}: {count:,} ({percentage:.1f}%)")
        
        # å°æ—¶åˆ†å¸ƒ
        if self.stats['hourly_requests']:
            print(f"\nâ° å°æ—¶åˆ†å¸ƒ:")
            for hour in range(24):
                count = self.stats['hourly_requests'][hour]
                if count > 0:
                    percentage = (count / self.stats['total_requests']) * 100
                    bar = "â–ˆ" * int(percentage / 2)
                    print(f"  {hour:02d}:00 {bar} {count:,} ({percentage:.1f}%)")
        
        # é”™è¯¯è¯¦æƒ…
        if self.stats['errors'] and not self.errors_only:
            print(f"\nâŒ æœ€è¿‘é”™è¯¯ (Top {min(10, len(self.stats['errors']))}):")
            for error in self.stats['errors'][-10:]:
                print(f"  è¡Œ{error['line']}: {error['ip']} - {error['status']} - {error['url']}")
        
        # ç”¨æˆ·ä»£ç†ç»Ÿè®¡
        if self.stats['user_agents'] and not self.errors_only:
            print(f"\nğŸ–¥ï¸ ç”¨æˆ·ä»£ç† (Top 5):")
            for ua, count in self.stats['user_agents'].most_common(5):
                percentage = (count / self.stats['total_requests']) * 100
                ua_display = ua[:60] + "..." if len(ua) > 60 else ua
                print(f"  {ua_display}: {count:,} ({percentage:.1f}%)")
    
    def save_report(self, output_file):
        """ä¿å­˜åˆ†ææŠ¥å‘Šåˆ°æ–‡ä»¶"""
        report_data = {
            'timestamp': datetime.now().isoformat(),
            'log_file': self.log_file,
            'total_requests': self.stats['total_requests'],
            'error_count': len(self.stats['errors']),
            'top_ips': dict(self.stats['ips'].most_common(self.top_count)),
            'top_urls': dict(self.stats['urls'].most_common(self.top_count)),
            'status_codes': dict(self.stats['status_codes']),
            'methods': dict(self.stats['methods']),
            'hourly_distribution': dict(self.stats['hourly_requests'])
        }
        
        with open(output_file, 'w') as f:
            json.dump(report_data, f, indent=2)
        
        print(f"ğŸ“„ æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_file}")

def main():
    parser = argparse.ArgumentParser(description='æ—¥å¿—åˆ†æè„šæœ¬')
    parser.add_argument('log_file', help='æ—¥å¿—æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--format', choices=['nginx', 'apache', 'json'], 
                       default='nginx', help='æ—¥å¿—æ ¼å¼')
    parser.add_argument('--errors-only', action='store_true', 
                       help='åªåˆ†æé”™è¯¯è¯·æ±‚')
    parser.add_argument('--top', type=int, default=10, 
                       help='æ˜¾ç¤ºTop Nç»“æœ')
    parser.add_argument('--output', help='ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶')
    
    args = parser.parse_args()
    
    analyzer = LogAnalyzer(
        log_file=args.log_file,
        log_format=args.format,
        errors_only=args.errors_only,
        top_count=args.top
    )
    
    analyzer.analyze_log()
    analyzer.print_report()
    
    if args.output:
        analyzer.save_report(args.output)

if __name__ == "__main__":
    main()
